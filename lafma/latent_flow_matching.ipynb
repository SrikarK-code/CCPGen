{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxlZK1SHkgl9"
      },
      "source": [
        "## workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGFeB3nUkW7_"
      },
      "source": [
        "a) Input: scVI embeddings of cell states\n",
        "b) Output: Generated protein sequences\n",
        "\n",
        "Process Flow:\n",
        "\n",
        "scVI embeddings → UNetModel → Flow Matching → Protein Decoder → Protein Sequence\n",
        "\n",
        "1. Input Preparation:\n",
        "   - Start with scVI (single-cell Variational Inference) embeddings of cell states.\n",
        "   - These embeddings are high-dimensional vectors (e.g., 128 dimensions) representing cellular gene expression profiles.\n",
        "   - The scVI embeddings are generated using a separate scVI model trained on single-cell RNA sequencing data.\n",
        "\n",
        "2. Model Architecture Overview:\n",
        "   The system consists of several key components:\n",
        "   a) UNetModel: The core generative model\n",
        "   b) FlowMatchingTrainer: Manages the flow matching process\n",
        "   c) ProtT5Encoder: Encodes protein sequences (for training)\n",
        "   d) ProtT5Decoder: Decodes latent representations to protein sequences\n",
        "\n",
        "3. UNetModel Detailed Architecture:\n",
        "   3.1. Initialization:\n",
        "   - The UNetModel is initialized with parameters like input/output channels, number of ResBlocks, attention resolutions, etc.\n",
        "   - Key components are created: time embedder, input blocks, middle block, output blocks.\n",
        "\n",
        "   3.2. Time Embedding:\n",
        "   - Function: timestep_embedding\n",
        "   - Converts a scalar timestep to a high-dimensional vector using sinusoidal functions.\n",
        "   - This embedding is further processed through a small MLP (self.time_embed).\n",
        "\n",
        "   3.3. Input Blocks:\n",
        "   - A series of TimestepEmbedSequential modules, each containing:\n",
        "     a) ResBlock: Combines feature maps with time embeddings\n",
        "     b) AttentionBlock or SpatialTransformer: For self-attention mechanisms\n",
        "     c) Downsample: Reduces spatial dimensions (if applicable)\n",
        "\n",
        "   3.4. Middle Block:\n",
        "   - Contains ResBlocks and Attention mechanisms for global reasoning.\n",
        "\n",
        "   3.5. Output Blocks:\n",
        "   - Mirror the input blocks, but with Upsample layers instead of Downsample.\n",
        "   - Use skip connections from input blocks.\n",
        "\n",
        "   3.6. Final Output Layer:\n",
        "   - Normalization followed by a convolution to produce the output channels.\n",
        "\n",
        "4. Detailed Component Breakdown:\n",
        "   4.1. ResBlock:\n",
        "   - Residual block that processes features and incorporates time embeddings.\n",
        "   - Contains normalization layers, convolutions, and optional up/downsampling.\n",
        "   - Uses checkpoint function for memory-efficient backpropagation.\n",
        "\n",
        "   4.2. AttentionBlock:\n",
        "   - Self-attention mechanism allowing interaction between different parts of the sequence.\n",
        "   - Uses QKVAttention for efficient attention computation.\n",
        "\n",
        "   4.3. SpatialTransformer:\n",
        "   - More sophisticated attention mechanism with multiple transformer layers.\n",
        "   - Each layer contains self-attention and feed-forward networks.\n",
        "\n",
        "   4.4. CrossAttention:\n",
        "   - Attention mechanism that can attend to a separate context (used in SpatialTransformer).\n",
        "   - Splits input into query, key, and value before computing attention.\n",
        "\n",
        "   4.5. FeedForward:\n",
        "   - Simple feedforward network used in transformer blocks.\n",
        "   - Contains two linear layers with GELU activation and dropout.\n",
        "\n",
        "   4.6. Upsample and Downsample:\n",
        "   - Handle changes in spatial dimensions of feature maps.\n",
        "   - Use either interpolation or transposed convolutions.\n",
        "\n",
        "   4.7. GroupNorm32:\n",
        "   - Custom group normalization for improved training stability.\n",
        "\n",
        "   4.8. TimestepEmbedSequential:\n",
        "   - Sequential module that handles passing of timestep embeddings to appropriate submodules.\n",
        "\n",
        "5. FlowMatchingTrainer:\n",
        "   - Manages the training process of the UNetModel.\n",
        "   - Implements the forward process (adding noise) and reverse process (denoising).\n",
        "   - Uses a noise schedule to control the amount of noise added at each timestep.\n",
        "   - Computes loss based on the model's ability to predict the noise added.\n",
        "\n",
        "6. ProtT5Encoder (for training):\n",
        "   - Utilizes a pre-trained ProtT5 model to encode protein sequences into a latent space.\n",
        "   - Processes amino acid sequences into a high-dimensional representation.\n",
        "\n",
        "7. ProtT5Decoder (for inference):\n",
        "   - Converts latent representations back into amino acid sequences.\n",
        "   - Uses beam search or other decoding strategies to generate the final protein sequence.\n",
        "\n",
        "8. Training Process:\n",
        "   8.1. Data Preparation:\n",
        "   - Batch of scVI embeddings and corresponding protein sequences are loaded.\n",
        "   - Protein sequences are encoded using ProtT5Encoder.\n",
        "\n",
        "   8.2. Forward Pass:\n",
        "   - Random timesteps are generated for each sample in the batch.\n",
        "   - Noise is added to the encoded protein sequences based on the timesteps.\n",
        "   - The UNetModel processes the noisy encodings, conditioned on scVI embeddings and timesteps.\n",
        "\n",
        "   8.3. Loss Computation:\n",
        "   - The model's output is compared to the true noise added.\n",
        "   - Loss is calculated (usually mean squared error).\n",
        "\n",
        "   8.4. Backpropagation:\n",
        "   - Gradients are computed and model parameters are updated.\n",
        "\n",
        "9. Inference Process:\n",
        "   9.1. Start with an scVI embedding of a cell state.\n",
        "   9.2. Generate random noise as the starting point.\n",
        "   9.3. Gradually denoise using the UNetModel:\n",
        "      - For each timestep (from most noisy to least):\n",
        "        - Pass the current noisy sample through the UNetModel.\n",
        "        - Use the model's prediction to update the sample.\n",
        "   9.4. The final denoised representation is passed through the ProtT5Decoder.\n",
        "   9.5. The decoder outputs the generated protein sequence.\n",
        "\n",
        "10. Utility Functions:\n",
        "    - conv_nd: Creates 1D convolutions for our sequence data.\n",
        "    - zero_module: Initializes a module's parameters to zero.\n",
        "    - normalization: Applies GroupNorm32 normalization.\n",
        "    - checkpoint: Implements gradient checkpointing for memory efficiency.\n",
        "    - exists and default: Helper functions for handling optional parameters.\n",
        "\n",
        "Cool adaptations\n",
        "    - Adaptation of 2D UNet architecture to 1D protein sequences.\n",
        "        - Unet in original model was used for the audio representations (spectograms)\n",
        "        - While we do use protein embeddings (like those from ProtT5), the UNet in our case still operates on a 1D sequence of these embeddings.\n",
        "        - Each position in this sequence corresponds to an amino acid, but is represented by a high-dimensional vector.\n",
        "        - The UNet processes this sequence of vectors, maintaining the 1D structure of the protein\n",
        "            - each element of the sequence is itself a rich high-dimensional representation (1280)\n",
        "    - Integration of flow matching with protein language models.\n",
        "    - Use of scVI embeddings as conditional input for targeted protein generation.\n",
        "\n",
        "\n",
        "Loss:\n",
        "θ^ = argmin_θ E_t,z_t ||u_θ(z_t, t, c) - v_t||^2\n",
        "Where:\n",
        "\n",
        "u_θ is your flow matching model (UNet)\n",
        "z_t is the scVI embedding at time t\n",
        "t is the timestep\n",
        "c is your context (which we'll discuss next)\n",
        "v_t is the target velocity (z_1 - (1-σ_min)z_0 in the optimal transport formulation)\n",
        "\n",
        "\n",
        "UNet\n",
        "This 1D UNet processes the scVI latent representations, which encode cellular states, through a series of downsampling and upsampling operations.\n",
        "The input blocks progressively reduce the spatial dimensions while increasing the channel depth, capturing hierarchical features.\n",
        "The middle block, with its deep channel representation, allows for global reasoning across the entire sequence.\n",
        "The output blocks then gradually upsample the representation back to the original dimensions, utilizing skip connections to preserve fine-grained information.\n",
        "Time embeddings are crucial, allowing the model to understand its position in the generation process.\n",
        "These embeddings are added to the input at each step, guiding the transformation from noise to protein sequence.\n",
        "Attention mechanisms, implemented either as AttentionBlocks or SpatialTransformers, enable the model to capture long-range dependencies critical for protein structure.\n",
        "The ResBlocks incorporate both the current state and the time embedding, allowing for time-dependent processing at each level.\n",
        "The context dimension, which could include additional information like pseudotime or motif data, is integrated through the SpatialTransformer blocks, providing extra conditioning for the generation process.\n",
        "The model's output represents the velocity field in the flow matching framework, predicting how the latent representation should change at each step to transform noise into a meaningful protein sequence representation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-njBgLzltjL"
      },
      "source": [
        "## library installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6I50Tquluub",
        "outputId": "6022f455-f1ad-45a5-aa0d-3a56b3623ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Collecting anndata\n",
            "  Downloading anndata-0.10.8-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting scvi-tools\n",
            "  Downloading scvi_tools-1.1.5-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting scanpy\n",
            "  Downloading scanpy-1.10.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting array-api-compat!=1.5,>1.4 (from anndata)\n",
            "  Downloading array_api_compat-1.8-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata) (1.2.2)\n",
            "Requirement already satisfied: h5py>=3.1 in /usr/local/lib/python3.10/dist-packages (from anndata) (3.11.0)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from anndata) (8.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from anndata) (24.1)\n",
            "Requirement already satisfied: pandas!=2.1.0rc0,!=2.1.2,>=1.4 in /usr/local/lib/python3.10/dist-packages (from anndata) (2.1.4)\n",
            "Collecting docrep>=0.3.2 (from scvi-tools)\n",
            "  Downloading docrep-0.3.2.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: flax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.8.4)\n",
            "Requirement already satisfied: jax>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.26)\n",
            "Requirement already satisfied: jaxlib>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.4.26+cuda12.cudnn89)\n",
            "Collecting lightning<2.2,>=2.0 (from scvi-tools)\n",
            "  Downloading lightning-2.1.4-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ml-collections>=0.1.1 (from scvi-tools)\n",
            "  Downloading ml_collections-0.1.1.tar.gz (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mudata>=0.1.2 (from scvi-tools)\n",
            "  Downloading mudata-0.3.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting numpyro>=0.12.1 (from scvi-tools)\n",
            "  Downloading numpyro-0.15.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (0.2.2)\n",
            "Collecting pyro-ppl>=1.6.0 (from scvi-tools)\n",
            "  Downloading pyro_ppl-1.9.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (13.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (1.3.2)\n",
            "Collecting torchmetrics>=0.11.0 (from scvi-tools)\n",
            "  Downloading torchmetrics-1.4.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: tqdm>=4.56.0 in /usr/local/lib/python3.10/dist-packages (from scvi-tools) (4.66.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy) (1.4.2)\n",
            "Collecting legacy-api-wrap>=1.4 (from scanpy)\n",
            "  Downloading legacy_api_wrap-1.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.10/dist-packages (from scanpy) (3.7.1)\n",
            "Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.60.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.5.6)\n",
            "Collecting pynndescent>=0.5 (from scanpy)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: seaborn>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.13.1)\n",
            "Collecting session-info (from scanpy)\n",
            "  Downloading session_info-1.0.0.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy) (0.14.2)\n",
            "Collecting umap-learn!=0.5.0,>=0.5 (from scanpy)\n",
            "  Downloading umap_learn-0.5.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from docrep>=0.3.2->scvi-tools) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.4->scvi-tools) (3.3.0)\n",
            "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning<2.2,>=2.0->scvi-tools)\n",
            "  Downloading lightning_utilities-0.11.6-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytorch-lightning (from lightning<2.2,>=2.0->scvi-tools)\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6->scanpy) (2.8.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (1.4.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections>=0.1.1->scvi-tools) (21.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.56->scanpy) (0.43.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from numpyro>=0.12.1->scvi-tools) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=2.1.0rc0,!=2.1.2,>=1.4->anndata) (2024.1)\n",
            "Collecting pyro-api>=0.1.1 (from pyro-ppl>=1.6.0->scvi-tools)\n",
            "  Downloading pyro_api-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->scvi-tools) (2.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.2->scvi-tools) (3.5.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (1.0.8)\n",
            "Requirement already satisfied: orbax-checkpoint in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.5.23)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax->scvi-tools) (0.1.63)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: chex>=0.1.86 in /usr/local/lib/python3.10/dist-packages (from optax->scvi-tools) (0.1.86)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Collecting stdlib_list (from session-info->scanpy)\n",
            "  Downloading stdlib_list-0.10.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.86->optax->scvi-tools) (0.12.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities<2.0,>=0.8.0->lightning<2.2,>=2.0->scvi-tools) (71.0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->scvi-tools) (0.1.2)\n",
            "Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.7.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (1.6.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint->flax->scvi-tools) (3.20.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2025.0,>=2022.5.0->lightning<2.2,>=2.0->scvi-tools) (4.0.3)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath,epy]->orbax-checkpoint->flax->scvi-tools) (3.19.2)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading anndata-0.10.8-py3-none-any.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/124.4 kB\u001b[0m \u001b[31m49.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scvi_tools-1.1.5-py3-none-any.whl (387 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m387.7/387.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scanpy-1.10.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading array_api_compat-1.8-py3-none-any.whl (38 kB)\n",
            "Downloading legacy_api_wrap-1.4-py3-none-any.whl (15 kB)\n",
            "Downloading lightning-2.1.4-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mudata-0.3.0-py3-none-any.whl (39 kB)\n",
            "Downloading numpyro-0.15.2-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.1/348.1 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyro_ppl-1.9.1-py3-none-any.whl (755 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.4.1-py3-none-any.whl (866 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m866.2/866.2 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading umap_learn-0.5.6-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.6-py3-none-any.whl (26 kB)\n",
            "Downloading pyro_api-0.1.2-py3-none-any.whl (11 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stdlib_list-0.10.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: docrep, ml-collections, session-info\n",
            "  Building wheel for docrep (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docrep: filename=docrep-0.3.2-py3-none-any.whl size=19876 sha256=dc72d410ed80cd1adfa640cd3c63e74fceb020d1db3282f9344d66d4543cfc78\n",
            "  Stored in directory: /root/.cache/pip/wheels/c3/64/48/03c38d8d906159eaa210b3c548fdb590eb3e2a4a5745ae2172\n",
            "  Building wheel for ml-collections (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ml-collections: filename=ml_collections-0.1.1-py3-none-any.whl size=94506 sha256=4e3eb31cee52e1316a0b6bd1d849dfe1d8aa4fb3a879c82355b0e2e9d8d00e4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/89/c9/a9b87790789e94aadcfc393c283e3ecd5ab916aed0a31be8fe\n",
            "  Building wheel for session-info (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for session-info: filename=session_info-1.0.0-py3-none-any.whl size=8023 sha256=303bfc919187653cc3d5d82c41599adeb77ee15ad29c59fff463e6a0dc71316b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/aa/b9/eb5d4031476ec10802795b97ccf937b9bd998d68a9b268765a\n",
            "Successfully built docrep ml-collections session-info\n",
            "Installing collected packages: pyro-api, array-api-compat, stdlib_list, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ml-collections, lightning-utilities, legacy-api-wrap, docrep, session-info, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pynndescent, nvidia-cusolver-cu12, numpyro, anndata, umap-learn, mudata, torchmetrics, scanpy, pyro-ppl, pytorch-lightning, lightning, scvi-tools\n",
            "Successfully installed anndata-0.10.8 array-api-compat-1.8 docrep-0.3.2 legacy-api-wrap-1.4 lightning-2.1.4 lightning-utilities-0.11.6 ml-collections-0.1.1 mudata-0.3.0 numpyro-0.15.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 pynndescent-0.5.13 pyro-api-0.1.2 pyro-ppl-1.9.1 pytorch-lightning-2.3.3 scanpy-1.10.2 scvi-tools-1.1.5 session-info-1.0.0 stdlib_list-0.10.0 torchmetrics-1.4.1 umap-learn-0.5.6\n"
          ]
        }
      ],
      "source": [
        "!pip install torch anndata scvi-tools einops numpy scipy transformers scanpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-e-EUQyklC2"
      },
      "source": [
        "## utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g37xH4c6kO8O"
      },
      "outputs": [],
      "source": [
        "# Copyright (c) 2023 Amphion.\n",
        "#\n",
        "# This source code is licensed under the MIT license found in the\n",
        "# LICENSE file in the root directory of this source tree.\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class AbstractDistribution:\n",
        "    def sample(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def mode(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class DiracDistribution(AbstractDistribution):\n",
        "    def __init__(self, value):\n",
        "        self.value = value\n",
        "\n",
        "    def sample(self):\n",
        "        return self.value\n",
        "\n",
        "    def mode(self):\n",
        "        return self.value\n",
        "\n",
        "\n",
        "class DiagonalGaussianDistribution(object):\n",
        "    def __init__(self, parameters, deterministic=False):\n",
        "        self.parameters = parameters\n",
        "        self.mean, self.logvar = torch.chunk(parameters, 2, dim=1)\n",
        "        self.logvar = torch.clamp(self.logvar, -30.0, 20.0)\n",
        "        self.deterministic = deterministic\n",
        "        self.std = torch.exp(0.5 * self.logvar)\n",
        "        self.var = torch.exp(self.logvar)\n",
        "        if self.deterministic:\n",
        "            self.var = self.std = torch.zeros_like(self.mean).to(\n",
        "                device=self.parameters.device\n",
        "            )\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.mean + self.std * torch.randn(self.mean.shape).to(\n",
        "            device=self.parameters.device\n",
        "        )\n",
        "        return x\n",
        "\n",
        "    def kl(self, other=None):\n",
        "        if self.deterministic:\n",
        "            return torch.Tensor([0.0])\n",
        "        else:\n",
        "            if other is None:\n",
        "                return 0.5 * torch.sum(\n",
        "                    torch.pow(self.mean, 2) + self.var - 1.0 - self.logvar,\n",
        "                    dim=[1, 2, 3],\n",
        "                )\n",
        "            else:\n",
        "                return 0.5 * torch.sum(\n",
        "                    torch.pow(self.mean - other.mean, 2) / other.var\n",
        "                    + self.var / other.var\n",
        "                    - 1.0\n",
        "                    - self.logvar\n",
        "                    + other.logvar,\n",
        "                    dim=[1, 2, 3],\n",
        "                )\n",
        "\n",
        "    def nll(self, sample, dims=[1, 2, 3]):\n",
        "        if self.deterministic:\n",
        "            return torch.Tensor([0.0])\n",
        "        logtwopi = np.log(2.0 * np.pi)\n",
        "        return 0.5 * torch.sum(\n",
        "            logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var,\n",
        "            dim=dims,\n",
        "        )\n",
        "\n",
        "    def mode(self):\n",
        "        return self.mean\n",
        "\n",
        "\n",
        "def normal_kl(mean1, logvar1, mean2, logvar2):\n",
        "    \"\"\"\n",
        "    source: https://github.com/openai/guided-diffusion/blob/27c20a8fab9cb472df5d6bdd6c8d11c8f430b924/guided_diffusion/losses.py#L12\n",
        "    Compute the KL divergence between two gaussians.\n",
        "    Shapes are automatically broadcasted, so batches can be compared to\n",
        "    scalars, among other use cases.\n",
        "    \"\"\"\n",
        "    tensor = None\n",
        "    for obj in (mean1, logvar1, mean2, logvar2):\n",
        "        if isinstance(obj, torch.Tensor):\n",
        "            tensor = obj\n",
        "            break\n",
        "    assert tensor is not None, \"at least one argument must be a Tensor\"\n",
        "\n",
        "    # Force variances to be Tensors. Broadcasting helps convert scalars to\n",
        "    # Tensors, but it does not work for torch.exp().\n",
        "    logvar1, logvar2 = [\n",
        "        x if isinstance(x, torch.Tensor) else torch.tensor(x).to(tensor)\n",
        "        for x in (logvar1, logvar2)\n",
        "    ]\n",
        "\n",
        "    return 0.5 * (\n",
        "        -1.0\n",
        "        + logvar2\n",
        "        - logvar1\n",
        "        + torch.exp(logvar1 - logvar2)\n",
        "        + ((mean1 - mean2) ** 2) * torch.exp(-logvar2)\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nAl6JpQjkO-k"
      },
      "outputs": [],
      "source": [
        "from abc import abstractmethod\n",
        "from functools import partial\n",
        "import math\n",
        "from typing import Iterable\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from einops import repeat\n",
        "def Normalize(in_channels):\n",
        "    return torch.nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)\n",
        "\n",
        "def count_flops_attn(model, _x, y):\n",
        "    b, c, *spatial = y[0].shape\n",
        "    num_spatial = int(np.prod(spatial))\n",
        "    matmul_ops = 2 * b * (num_spatial**2) * c\n",
        "    model.total_ops += torch.DoubleTensor([matmul_ops])\n",
        "\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(\n",
        "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "    ).to(device=timesteps.device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2:\n",
        "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "    return embedding\n",
        "\n",
        "def conv_nd(dims, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Create a 1D, 2D, or 3D convolution module.\n",
        "    \"\"\"\n",
        "    if dims == 1:\n",
        "        return nn.Conv1d(*args, **kwargs)\n",
        "    elif dims == 2:\n",
        "        return nn.Conv2d(*args, **kwargs)\n",
        "    elif dims == 3:\n",
        "        return nn.Conv3d(*args, **kwargs)\n",
        "    raise ValueError(f\"unsupported dimensions: {dims}\")\n",
        "\n",
        "def linear(*args, **kwargs):\n",
        "    \"\"\"\n",
        "    Create a linear module.\n",
        "    \"\"\"\n",
        "    return nn.Linear(*args, **kwargs)\n",
        "\n",
        "def avg_pool_nd(dims, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Create a 1D, 2D, or 3D average pooling module.\n",
        "    \"\"\"\n",
        "    if dims == 1:\n",
        "        return nn.AvgPool1d(*args, **kwargs)\n",
        "    elif dims == 2:\n",
        "        return nn.AvgPool2d(*args, **kwargs)\n",
        "    elif dims == 3:\n",
        "        return nn.AvgPool3d(*args, **kwargs)\n",
        "    raise ValueError(f\"unsupported dimensions: {dims}\")\n",
        "\n",
        "def zero_module(module):\n",
        "    \"\"\"\n",
        "    Zero out the parameters of a module and return it.\n",
        "    \"\"\"\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "def normalization(channels):\n",
        "    \"\"\"\n",
        "    Make a standard normalization layer.\n",
        "    :param channels: number of input channels.\n",
        "    :return: an nn.Module for normalization.\n",
        "    \"\"\"\n",
        "    return GroupNorm32(32, channels)\n",
        "\n",
        "class GroupNorm32(nn.GroupNorm):\n",
        "    def forward(self, x):\n",
        "        return super().forward(x.float()).type(x.dtype)\n",
        "\n",
        "def checkpoint(func, inputs, params, flag):\n",
        "    \"\"\"\n",
        "    Evaluate a function without caching intermediate activations, allowing for\n",
        "    reduced memory at the expense of extra compute in the backward pass.\n",
        "    \"\"\"\n",
        "    if flag:\n",
        "        args = tuple(inputs) + tuple(params)\n",
        "        return CheckpointFunction.apply(func, len(inputs), *args)\n",
        "    else:\n",
        "        return func(*inputs)\n",
        "\n",
        "class TimestepBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Any module where forward() takes timestep embeddings as a second argument.\n",
        "    \"\"\"\n",
        "    @abstractmethod\n",
        "    def forward(self, x, emb):\n",
        "        \"\"\"\n",
        "        Apply the module to `x` given `emb` timestep embeddings.\n",
        "        \"\"\"\n",
        "\n",
        "class TimestepEmbedSequential(nn.Sequential, TimestepBlock):\n",
        "    \"\"\"\n",
        "    A sequential module that passes timestep embeddings to the children that\n",
        "    support it as an extra input.\n",
        "    \"\"\"\n",
        "    def forward(self, x, emb, context=None):\n",
        "        for layer in self:\n",
        "            if isinstance(layer, TimestepBlock):\n",
        "                x = layer(x, emb)\n",
        "            elif isinstance(layer, SpatialTransformer):\n",
        "                x = layer(x, context)\n",
        "            else:\n",
        "                x = layer(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "w0P4txPYkPAp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, query_dim, context_dim=None, heads=8, dim_head=64, dropout=0.0):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        context_dim = default(context_dim, query_dim)\n",
        "\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "\n",
        "        self.to_q = nn.Linear(query_dim, inner_dim, bias=False)\n",
        "        self.to_k = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "        self.to_v = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Linear(inner_dim, query_dim),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, context=None, mask=None):\n",
        "        h = self.heads\n",
        "\n",
        "        q = self.to_q(x)\n",
        "        context = default(context, x)\n",
        "        k = self.to_k(context)\n",
        "        v = self.to_v(context)\n",
        "\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=h), (q, k, v))\n",
        "\n",
        "        sim = torch.einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
        "\n",
        "        if exists(mask):\n",
        "            mask = rearrange(mask, 'b ... -> b (...)')\n",
        "            max_neg_value = -torch.finfo(sim.dtype).max\n",
        "            mask = repeat(mask, 'b j -> (b h) () j', h=h)\n",
        "            sim.masked_fill_(~mask, max_neg_value)\n",
        "\n",
        "        attn = sim.softmax(dim=-1)\n",
        "\n",
        "        out = torch.einsum('b i j, b j d -> b i d', attn, v)\n",
        "        out = rearrange(out, '(b h) n d -> b n (h d)', h=h)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, dim_out=None, mult=4, glu=False, dropout=0.0):\n",
        "        super().__init__()\n",
        "        inner_dim = int(dim * mult)\n",
        "        dim_out = default(dim_out, dim)\n",
        "        project_in = nn.Sequential(\n",
        "            nn.Linear(dim, inner_dim),\n",
        "            nn.GELU()\n",
        "        ) if not glu else GEGLU(dim, inner_dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            project_in,\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(inner_dim, dim_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if callable(d) else d\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(dim_in, dim_out * 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, gate = self.proj(x).chunk(2, dim=-1)\n",
        "        return x * F.gelu(gate)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, channels, use_conv, dims=1, out_channels=None, padding=1):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_conv = use_conv\n",
        "        self.dims = dims\n",
        "        if use_conv:\n",
        "            self.conv = conv_nd(dims, self.channels, self.out_channels, 3, padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        if self.dims == 3:\n",
        "            x = F.interpolate(x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode=\"nearest\")\n",
        "        else:\n",
        "            x = F.interpolate(x, scale_factor=2, mode=\"nearest\")\n",
        "        if self.use_conv:\n",
        "            x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, channels, use_conv, dims=1, out_channels=None, padding=1):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_conv = use_conv\n",
        "        self.dims = dims\n",
        "        stride = 2 if dims != 3 else (1, 2, 2)\n",
        "        if use_conv:\n",
        "            self.op = conv_nd(dims, self.channels, self.out_channels, 3, stride=stride, padding=padding)\n",
        "        else:\n",
        "            assert self.channels == self.out_channels\n",
        "            self.op = avg_pool_nd(dims, kernel_size=stride, stride=stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        assert x.shape[1] == self.channels\n",
        "        return self.op(x)\n",
        "\n",
        "class ResBlock(TimestepBlock):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        emb_channels,\n",
        "        dropout,\n",
        "        out_channels=None,\n",
        "        use_conv=False,\n",
        "        use_scale_shift_norm=False,\n",
        "        dims=1,\n",
        "        use_checkpoint=False,\n",
        "        up=False,\n",
        "        down=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.emb_channels = emb_channels\n",
        "        self.dropout = dropout\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_conv = use_conv\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.use_scale_shift_norm = use_scale_shift_norm\n",
        "\n",
        "        self.in_layers = nn.Sequential(\n",
        "            normalization(channels),\n",
        "            nn.SiLU(),\n",
        "            conv_nd(dims, channels, self.out_channels, 3, padding=1),\n",
        "        )\n",
        "\n",
        "        self.updown = up or down\n",
        "\n",
        "        if up:\n",
        "            self.h_upd = Upsample(channels, False, dims)\n",
        "            self.x_upd = Upsample(channels, False, dims)\n",
        "        elif down:\n",
        "            self.h_upd = Downsample(channels, False, dims)\n",
        "            self.x_upd = Downsample(channels, False, dims)\n",
        "        else:\n",
        "            self.h_upd = self.x_upd = nn.Identity()\n",
        "\n",
        "        self.emb_layers = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            linear(\n",
        "                emb_channels,\n",
        "                2 * self.out_channels if use_scale_shift_norm else self.out_channels,\n",
        "            ),\n",
        "        )\n",
        "        self.out_layers = nn.Sequential(\n",
        "            normalization(self.out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(p=dropout),\n",
        "            zero_module(conv_nd(dims, self.out_channels, self.out_channels, 3, padding=1)),\n",
        "        )\n",
        "\n",
        "        if self.out_channels == channels:\n",
        "            self.skip_connection = nn.Identity()\n",
        "        elif use_conv:\n",
        "            self.skip_connection = conv_nd(dims, channels, self.out_channels, 3, padding=1)\n",
        "        else:\n",
        "            self.skip_connection = conv_nd(dims, channels, self.out_channels, 1)\n",
        "\n",
        "    def forward(self, x, emb):\n",
        "        return checkpoint(self._forward, (x, emb), self.parameters(), self.use_checkpoint)\n",
        "\n",
        "    def _forward(self, x, emb):\n",
        "        if self.updown:\n",
        "            in_rest, in_conv = self.in_layers[:-1], self.in_layers[-1]\n",
        "            h = in_rest(x)\n",
        "            h = self.h_upd(h)\n",
        "            x = self.x_upd(x)\n",
        "            h = in_conv(h)\n",
        "        else:\n",
        "            h = self.in_layers(x)\n",
        "        emb_out = self.emb_layers(emb).type(h.dtype)\n",
        "        while len(emb_out.shape) < len(h.shape):\n",
        "            emb_out = emb_out[..., None]\n",
        "        if self.use_scale_shift_norm:\n",
        "            out_norm, out_rest = self.out_layers[0], self.out_layers[1:]\n",
        "            scale, shift = torch.chunk(emb_out, 2, dim=1)\n",
        "            h = out_norm(h) * (1 + scale) + shift\n",
        "            h = out_rest(h)\n",
        "        else:\n",
        "            h = h + emb_out\n",
        "            h = self.out_layers(h)\n",
        "        return self.skip_connection(x) + h\n",
        "\n",
        "class QKVAttention(nn.Module):\n",
        "    def __init__(self, n_heads):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, qkv):\n",
        "        bs, width, length = qkv.shape\n",
        "        assert width % (3 * self.n_heads) == 0\n",
        "        ch = width // (3 * self.n_heads)\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "        scale = 1 / math.sqrt(math.sqrt(ch))\n",
        "        weight = torch.einsum(\n",
        "            \"bct,bcs->bts\",\n",
        "            (q * scale).view(bs * self.n_heads, ch, length),\n",
        "            (k * scale).view(bs * self.n_heads, ch, length),\n",
        "        )\n",
        "        weight = torch.softmax(weight.float(), dim=-1).type(weight.dtype)\n",
        "        a = torch.einsum(\"bts,bcs->bct\", weight, v.reshape(bs * self.n_heads, ch, length))\n",
        "        return a.reshape(bs, -1, length)\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        channels,\n",
        "        num_heads=1,\n",
        "        num_head_channels=-1,\n",
        "        use_checkpoint=False,\n",
        "        use_new_attention_order=False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        if num_head_channels == -1:\n",
        "            self.num_heads = num_heads\n",
        "        else:\n",
        "            assert channels % num_head_channels == 0\n",
        "            self.num_heads = channels // num_head_channels\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.norm = normalization(channels)\n",
        "        self.qkv = conv_nd(1, channels, channels * 3, 1)\n",
        "        self.attention = QKVAttention(self.num_heads)\n",
        "        self.proj_out = zero_module(conv_nd(1, channels, channels, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return checkpoint(self._forward, (x,), self.parameters(), self.use_checkpoint)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        b, c, *spatial = x.shape\n",
        "        x = x.reshape(b, c, -1)\n",
        "        qkv = self.qkv(self.norm(x))\n",
        "        h = self.attention(qkv)\n",
        "        h = self.proj_out(h)\n",
        "        return (x + h).reshape(b, c, *spatial)\n",
        "\n",
        "class SpatialTransformer(nn.Module):\n",
        "    def __init__(self, in_channels, n_heads, d_head, depth=1, dropout=0., context_dim=None):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        inner_dim = n_heads * d_head\n",
        "        self.norm = Normalize(in_channels)\n",
        "\n",
        "        self.proj_in = nn.Conv1d(in_channels, inner_dim, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [BasicTransformerBlock(inner_dim, n_heads, d_head, dropout=dropout, context_dim=context_dim)\n",
        "             for d in range(depth)]\n",
        "        )\n",
        "\n",
        "        self.proj_out = zero_module(nn.Conv1d(inner_dim, in_channels, kernel_size=1, stride=1, padding=0))\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        # note: if no context is given, cross-attention defaults to self-attention\n",
        "        b, c, s = x.shape\n",
        "        x_in = x\n",
        "        x = self.norm(x)\n",
        "        x = self.proj_in(x)\n",
        "        x = rearrange(x, 'b c s -> b s c')\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, context=context)\n",
        "        x = rearrange(x, 'b s c -> b c s')\n",
        "        x = self.proj_out(x)\n",
        "        return x + x_in\n",
        "\n",
        "class BasicTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, n_heads, d_head, dropout=0., context_dim=None, gated_ff=True, checkpoint=True):\n",
        "        super().__init__()\n",
        "        self.attn1 = CrossAttention(query_dim=dim, heads=n_heads, dim_head=d_head, dropout=dropout)\n",
        "        self.ff = FeedForward(dim, dropout=dropout, glu=gated_ff)\n",
        "        self.attn2 = CrossAttention(query_dim=dim, context_dim=context_dim,\n",
        "                                    heads=n_heads, dim_head=d_head, dropout=dropout)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.norm3 = nn.LayerNorm(dim)\n",
        "        self.checkpoint = checkpoint\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
        "\n",
        "    def _forward(self, x, context=None):\n",
        "        x = self.attn1(self.norm1(x)) + x\n",
        "        x = self.attn2(self.norm2(x), context=context) + x\n",
        "        x = self.ff(self.norm3(x)) + x\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht7z5O8ilEnK"
      },
      "source": [
        "## pretrained embedding modules (prott5, scvi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AQRVEnwZlULP"
      },
      "outputs": [],
      "source": [
        "from transformers import T5EncoderModel, T5Tokenizer\n",
        "import torch.nn as nn\n",
        "import re\n",
        "\n",
        "class ProtT5EncodingModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.protT5_model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
        "        self.protT5_tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "\n",
        "    def forward(self, sequence):\n",
        "        processed_seq = \" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence)))\n",
        "        ids = self.protT5_tokenizer(processed_seq, add_special_tokens=True, return_tensors=\"pt\", padding='longest')\n",
        "        input_ids = ids['input_ids'].to(self.protT5_model.device)\n",
        "        attention_mask = ids['attention_mask'].to(self.protT5_model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedding_repr = self.protT5_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        seq_emb = embedding_repr.last_hidden_state\n",
        "        return seq_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "72smUTRJkPCv"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "class ProtT5DecodingModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.protT5_model = T5ForConditionalGeneration.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "        self.protT5_tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_bfd\")\n",
        "\n",
        "    def forward(self, latent_repr, max_length=200):\n",
        "        outputs = self.protT5_model.generate(\n",
        "            inputs_embeds=latent_repr,\n",
        "            max_length=max_length,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "        decoded_sequences = self.protT5_tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        return decoded_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OeMMOtkGuWQP"
      },
      "outputs": [],
      "source": [
        "import scvi\n",
        "import scanpy as sc\n",
        "import numpy as np\n",
        "\n",
        "# encode pseudotime and latent representations\n",
        "\n",
        "class SCVIEncodingModule:\n",
        "    def __init__(self):\n",
        "        self.latent_representations = {}\n",
        "        self.pseudotime_representations = {}\n",
        "\n",
        "    def encode(self, adata_dict):\n",
        "        for cell_type, adata in adata_dict.items():\n",
        "            print(f\"Training and embedding for cell type: {cell_type}...\")\n",
        "\n",
        "            adata_copy = adata.copy()\n",
        "\n",
        "            nan_count = np.isnan(adata_copy.X).sum()\n",
        "            if nan_count > 0:\n",
        "                print(f\"There are {nan_count} NaN values in adata_copy.X for cell type: {cell_type}\")\n",
        "            else:\n",
        "                print(f\"No NaN values found in adata_copy.X for cell type: {cell_type}\")\n",
        "\n",
        "            latent = adata_copy.obsm['X_scvi']\n",
        "            pseudotime = adata_copy.obs['dpt_pseudotime']\n",
        "\n",
        "            # Store latent representation in the dictionary\n",
        "            self.latent_representations[cell_type] = latent\n",
        "            self.pseudotime_representations[cell_type] = pseudotime\n",
        "\n",
        "        print(\"Encoding completed.\")\n",
        "\n",
        "        return self.latent_representations, self.pseudotime_representations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBEPeCXzk3zn"
      },
      "source": [
        "## unet model (flow matching)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vtTtnoVYk9B-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomUNet1D(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        model_channels,\n",
        "        num_res_blocks,\n",
        "        attention_resolutions,\n",
        "        dropout=0,\n",
        "        channel_mult=(1, 2, 4, 8),\n",
        "        conv_resample=True,\n",
        "        use_checkpoint=False,\n",
        "        num_heads=8,\n",
        "        use_scale_shift_norm=False,\n",
        "        use_spatial_transformer=False,\n",
        "        transformer_depth=1,\n",
        "        context_dim=1,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.model_channels = model_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_res_blocks = num_res_blocks\n",
        "        self.attention_resolutions = attention_resolutions\n",
        "        self.dropout = dropout\n",
        "        self.channel_mult = channel_mult\n",
        "        self.conv_resample = conv_resample\n",
        "        self.use_checkpoint = use_checkpoint\n",
        "        self.num_heads = num_heads\n",
        "        self.use_spatial_transformer = use_spatial_transformer\n",
        "        self.context_dim = context_dim\n",
        "\n",
        "        self.context_proj = nn.Linear(context_dim, model_channels)\n",
        "        self.final_proj = nn.Linear(model_channels * 2, out_channels)  # *2 to account for concatenated context\n",
        "\n",
        "        time_embed_dim = model_channels * 4\n",
        "        self.time_embed = nn.Sequential(\n",
        "            nn.Linear(model_channels, time_embed_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_embed_dim, time_embed_dim),\n",
        "        )\n",
        "\n",
        "        self.input_blocks = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels, model_channels, 3, padding=1)\n",
        "        ])\n",
        "\n",
        "        ch = model_channels\n",
        "        input_block_chans = [model_channels]\n",
        "        ds = 1\n",
        "        for level, mult in enumerate(channel_mult):\n",
        "            for _ in range(num_res_blocks):\n",
        "                layers = [\n",
        "                    ResBlock1D(\n",
        "                        ch,\n",
        "                        time_embed_dim,\n",
        "                        dropout,\n",
        "                        out_channels=mult * model_channels,\n",
        "                        use_scale_shift_norm=use_scale_shift_norm,\n",
        "                    )\n",
        "                ]\n",
        "                ch = mult * model_channels\n",
        "                if ds in attention_resolutions:\n",
        "                    if use_spatial_transformer:\n",
        "                        layers.append(\n",
        "                            SpatialTransformer1D(\n",
        "                                ch, num_heads, context_dim, depth=transformer_depth\n",
        "                            )\n",
        "                        )\n",
        "                    else:\n",
        "                        layers.append(AttentionBlock1D(ch, num_heads=num_heads))\n",
        "                self.input_blocks.append(nn.Sequential(*layers))\n",
        "                input_block_chans.append(ch)\n",
        "            if level != len(channel_mult) - 1:\n",
        "                self.input_blocks.append(\n",
        "                    nn.Conv1d(ch, ch, 3, stride=2, padding=1)\n",
        "                )\n",
        "                input_block_chans.append(ch)\n",
        "                ds *= 2\n",
        "\n",
        "        self.middle_block = nn.Sequential(\n",
        "            ResBlock1D(\n",
        "                ch,\n",
        "                time_embed_dim,\n",
        "                dropout,\n",
        "                use_scale_shift_norm=use_scale_shift_norm,\n",
        "            ),\n",
        "            AttentionBlock1D(ch, num_heads=num_heads) if not use_spatial_transformer else\n",
        "            SpatialTransformer1D(ch, num_heads, context_dim, depth=transformer_depth),\n",
        "            ResBlock1D(\n",
        "                ch,\n",
        "                time_embed_dim,\n",
        "                dropout,\n",
        "                use_scale_shift_norm=use_scale_shift_norm,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        self.output_blocks = nn.ModuleList([])\n",
        "        for level, mult in list(enumerate(channel_mult))[::-1]:\n",
        "            for i in range(num_res_blocks + 1):\n",
        "                layers = [\n",
        "                    ResBlock1D(\n",
        "                        ch + input_block_chans.pop(),\n",
        "                        time_embed_dim,\n",
        "                        dropout,\n",
        "                        out_channels=model_channels * mult,\n",
        "                        use_scale_shift_norm=use_scale_shift_norm,\n",
        "                    )\n",
        "                ]\n",
        "                ch = model_channels * mult\n",
        "                if ds in attention_resolutions:\n",
        "                    if use_spatial_transformer:\n",
        "                        layers.append(\n",
        "                            SpatialTransformer1D(\n",
        "                                ch, num_heads, context_dim, depth=transformer_depth\n",
        "                            )\n",
        "                        )\n",
        "                    else:\n",
        "                        layers.append(AttentionBlock1D(ch, num_heads=num_heads))\n",
        "                if level and i == num_res_blocks:\n",
        "                    layers.append(nn.ConvTranspose1d(ch, ch, 4, stride=2, padding=1))\n",
        "                    ds //= 2\n",
        "                self.output_blocks.append(nn.Sequential(*layers))\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.GroupNorm(32, ch),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv1d(ch, out_channels, 3, padding=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, timesteps, context=None):\n",
        "      # x: [batch_size, 1024, 50]\n",
        "      # context: [batch_size, seq_len, context_dim]\n",
        "\n",
        "      x = x.transpose(1, 2)  # transpose shape: [batch_size, emb_dim, seqlen]\n",
        "      t_emb = self.time_embed(timestep_embedding(timesteps, self.model_channels))\n",
        "\n",
        "      h = x\n",
        "      hs = []\n",
        "      for module in self.input_blocks:\n",
        "          # print(\"Module type input blocks:\", type(module))\n",
        "          if isinstance(module, nn.Conv1d):\n",
        "              h = module(h)\n",
        "          elif isinstance(module, SpatialTransformer1D):\n",
        "            h = module(h, context)\n",
        "          elif isinstance(module, ResBlock1D):\n",
        "            h = module(h, t_emb)\n",
        "          elif isinstance(module, nn.Sequential):\n",
        "              for submodule in module:\n",
        "                  # print(\"submodule type input blocks:\", type(submodule))\n",
        "                  if isinstance(submodule, ResBlock1D):\n",
        "                      h = submodule(h, t_emb)\n",
        "                  elif isinstance(submodule, SpatialTransformer1D):\n",
        "                      h = submodule(h, context)\n",
        "                  else:\n",
        "                      h = submodule(h)\n",
        "          else:\n",
        "              h = module(h)\n",
        "          hs.append(h)\n",
        "\n",
        "      if isinstance(self.middle_block, nn.Sequential):\n",
        "          for submodule in self.middle_block:\n",
        "              if isinstance(submodule, ResBlock1D):\n",
        "                  h = submodule(h, t_emb)\n",
        "              elif isinstance(submodule, SpatialTransformer1D):\n",
        "                  h = submodule(h, context)\n",
        "              else:\n",
        "                  h = submodule(h)\n",
        "      else:\n",
        "          h = self.middle_block(h)\n",
        "\n",
        "      for module in self.output_blocks:\n",
        "          h = torch.cat([h, hs.pop()], dim=1)\n",
        "          if isinstance(module, nn.Sequential):\n",
        "              for submodule in module:\n",
        "                  if isinstance(submodule, ResBlock1D):\n",
        "                      h = submodule(h, t_emb)\n",
        "                  elif isinstance(submodule, SpatialTransformer1D):\n",
        "                      h = submodule(h, context)\n",
        "                  else:\n",
        "                      h = submodule(h)\n",
        "          elif isinstance(module, SpatialTransformer1D):\n",
        "            h = module(h, context)\n",
        "          elif isinstance(module, ResBlock1D):\n",
        "            h = module(h, t_emb)\n",
        "          else:\n",
        "              h = module(h)\n",
        "\n",
        "      output = self.out(h) # [batch_size, model_channels, seq_len]\n",
        "      output = output.transpose(1, 2)  # shape: [batch_size, seqlen, model_channels]\n",
        "\n",
        "      return output\n",
        "\n",
        "class ResBlock1D(nn.Module):\n",
        "    def __init__(self, channels, time_embed_dim, dropout, out_channels=None, use_scale_shift_norm=False):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.time_embed_dim = time_embed_dim\n",
        "        self.out_channels = out_channels or channels\n",
        "        self.use_scale_shift_norm = use_scale_shift_norm\n",
        "\n",
        "        self.in_layers = nn.Sequential(\n",
        "            nn.GroupNorm(32, channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv1d(channels, self.out_channels, 3, padding=1),\n",
        "        )\n",
        "        self.emb_layers = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_embed_dim, 2 * self.out_channels if use_scale_shift_norm else self.out_channels),\n",
        "        )\n",
        "        self.out_layers = nn.Sequential(\n",
        "            nn.GroupNorm(32, self.out_channels),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Conv1d(self.out_channels, self.out_channels, 3, padding=1),\n",
        "        )\n",
        "        if channels != self.out_channels:\n",
        "            self.skip_connection = nn.Conv1d(channels, self.out_channels, 1)\n",
        "        else:\n",
        "            self.skip_connection = nn.Identity()\n",
        "\n",
        "    def forward(self, x, emb):\n",
        "        h = self.in_layers(x)\n",
        "        emb_out = self.emb_layers(emb).unsqueeze(2)\n",
        "        if self.use_scale_shift_norm:\n",
        "            scale, shift = torch.chunk(emb_out, 2, dim=1)\n",
        "            h = self.out_layers[0](h) * (1 + scale) + shift\n",
        "            h = self.out_layers[1:](h)\n",
        "        else:\n",
        "            h = h + emb_out\n",
        "            h = self.out_layers(h)\n",
        "        return self.skip_connection(x) + h\n",
        "\n",
        "class AttentionBlock1D(nn.Module):\n",
        "    def __init__(self, channels, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.norm = nn.GroupNorm(32, channels)\n",
        "        self.qkv = nn.Conv1d(channels, channels * 3, 1)\n",
        "        self.attention = QKVAttention(num_heads)\n",
        "        self.proj_out = nn.Conv1d(channels, channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, s = x.shape\n",
        "        qkv = self.qkv(self.norm(x))\n",
        "        qkv = qkv.reshape(b * self.num_heads, -1, s)\n",
        "        h = self.attention(qkv)\n",
        "        h = h.reshape(b, -1, s)\n",
        "        return x + self.proj_out(h)\n",
        "\n",
        "class QKVAttention(nn.Module):\n",
        "    def __init__(self, n_heads):\n",
        "        super().__init__()\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "    def forward(self, qkv):\n",
        "        bs, width, length = qkv.shape\n",
        "        ch = width // (3 * self.n_heads)\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "        scale = 1 / math.sqrt(math.sqrt(ch))\n",
        "        weight = torch.einsum(\n",
        "            \"bct,bcs->bts\",\n",
        "            (q * scale).view(bs * self.n_heads, ch, length),\n",
        "            (k * scale).view(bs * self.n_heads, ch, length),\n",
        "        )\n",
        "        weight = torch.softmax(weight.float(), dim=-1).type(weight.dtype)\n",
        "        a = torch.einsum(\"bts,bcs->bct\", weight, v.reshape(bs * self.n_heads, ch, length))\n",
        "        return a.reshape(bs, -1, length)\n",
        "\n",
        "class SpatialTransformer1D(nn.Module):\n",
        "    def __init__(self, channels, num_heads, context_dim, depth=1):\n",
        "        super().__init__()\n",
        "        self.norm = nn.GroupNorm(32, channels)\n",
        "        inner_dim = channels\n",
        "        self.proj_in = nn.Conv1d(channels, inner_dim, 1)\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [BasicTransformerBlock(inner_dim, num_heads, context_dim) for _ in range(depth)]\n",
        "        )\n",
        "        self.proj_out = nn.Conv1d(inner_dim, channels, 1)\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        b, c, s = x.shape\n",
        "        x_in = x\n",
        "        x = self.norm(x)\n",
        "        x = self.proj_in(x)\n",
        "        x = x.permute(0, 2, 1).contiguous()\n",
        "        for block in self.transformer_blocks:\n",
        "            x = block(x, context)\n",
        "        x = x.permute(0, 2, 1).contiguous()\n",
        "        x = self.proj_out(x)\n",
        "        return x + x_in\n",
        "\n",
        "class BasicTransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads, context_dim):\n",
        "        super().__init__()\n",
        "        self.attn1 = CrossAttention(dim, dim, num_heads)\n",
        "        self.ff = FeedForward(dim)\n",
        "        self.attn2 = CrossAttention(dim, context_dim, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        self.norm3 = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        x = self.attn1(self.norm1(x)) + x\n",
        "        x = self.attn2(self.norm2(x), context=context) + x\n",
        "        x = self.ff(self.norm3(x)) + x\n",
        "        return x\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, query_dim, context_dim, num_heads, dim_head=64):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * num_heads\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.to_q = nn.Linear(query_dim, inner_dim, bias=False)\n",
        "        self.to_k = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "        self.to_v = nn.Linear(context_dim, inner_dim, bias=False)\n",
        "        self.to_out = nn.Linear(inner_dim, query_dim)\n",
        "\n",
        "    def forward(self, x, context=None):\n",
        "        h = self.num_heads\n",
        "\n",
        "        q = self.to_q(x)\n",
        "        context = x if context is None else context\n",
        "        k = self.to_k(context)\n",
        "        v = self.to_v(context)\n",
        "\n",
        "        q, k, v = map(lambda t: t.reshape(t.shape[0], -1, h, t.shape[-1] // h).permute(0, 2, 1, 3), (q, k, v))\n",
        "        sim = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale\n",
        "        attn = sim.softmax(dim=-1)\n",
        "        out = torch.einsum('bhij,bhjd->bhid', attn, v)\n",
        "        out = out.permute(0, 2, 1, 3).reshape(out.shape[0], -1, out.shape[-1] * h)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * mult, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def timestep_embedding(timesteps, dim, max_period=10000):\n",
        "    half = dim // 2\n",
        "    freqs = torch.exp(\n",
        "        -math.log(max_period) * torch.arange(start=0, end=half, dtype=torch.float32) / half\n",
        "    ).to(device=timesteps.device)\n",
        "    args = timesteps[:, None].float() * freqs[None]\n",
        "    embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "    if dim % 2:\n",
        "        embedding = torch.cat([embedding, torch.zeros_like(embedding[:, :1])], dim=-1)\n",
        "    return embedding\n",
        "\n",
        "class TimestepEmbedSequential(nn.Sequential):\n",
        "    def forward(self, x, emb, context=None):\n",
        "        for layer in self:\n",
        "            if isinstance(layer, ResBlock1D):\n",
        "                x = layer(x, emb)\n",
        "            elif isinstance(layer, SpatialTransformer1D):\n",
        "                x = layer(x, context)\n",
        "            elif isinstance(layer, nn.Conv1d) or isinstance(layer, nn.GroupNorm) or isinstance(layer, nn.ReLU):\n",
        "                x = layer(x)\n",
        "            else:\n",
        "                x = layer(x, emb, context)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOjxMpSTljVi"
      },
      "source": [
        "## ode solver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HN_dc7YsllVr"
      },
      "outputs": [],
      "source": [
        "from scipy.integrate import solve_ivp\n",
        "import numpy as np\n",
        "\n",
        "class ODESolverModule:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def ode_func(self, t, y, *args):\n",
        "        y_tensor = torch.tensor(y, dtype=torch.float32).unsqueeze(0)\n",
        "        t_tensor = torch.tensor([t], dtype=torch.float32)\n",
        "        with torch.no_grad():\n",
        "            dy_dt = self.model(y_tensor, t_tensor, *args).squeeze().numpy()\n",
        "        return dy_dt\n",
        "\n",
        "    def solve(self, y0, t_span, *args, method='RK45', **kwargs):\n",
        "        solution = solve_ivp(\n",
        "            fun=lambda t, y: self.ode_func(t, y, *args),\n",
        "            t_span=t_span,\n",
        "            y0=y0,\n",
        "            method=method,\n",
        "            **kwargs\n",
        "        )\n",
        "        return solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQZhv_Qwk3Rg"
      },
      "source": [
        "## flow trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2TZyCbPplciH"
      },
      "outputs": [],
      "source": [
        "class FlowMatchingTrainer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        init_type=\"gaussian\",\n",
        "        noise_scale=1.0,\n",
        "        reflow_t_schedule=\"uniform\",\n",
        "        use_ode_sampler=\"euler\",\n",
        "        sigma_var=0.0,\n",
        "        ode_tol=1e-5,\n",
        "        sample_N=25,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.init_type = init_type\n",
        "        self.noise_scale = noise_scale\n",
        "        self.reflow_t_schedule = reflow_t_schedule\n",
        "        self.use_ode_sampler = use_ode_sampler\n",
        "        self.sigma_var = sigma_var\n",
        "        self.ode_tol = ode_tol\n",
        "        self.sample_N = sample_N\n",
        "        self.T = 1\n",
        "        self.eps = 1e-3\n",
        "        self.sigma_t = lambda t: (1.0 - t) * sigma_var\n",
        "\n",
        "    def forward(self, x_0, prot_target, c):\n",
        "        # x_0: scVI embeddings [batch_size, 1024, 50]\n",
        "        # prot_target: ProtT5 embeddings [batch_size, seq_len, 1024]\n",
        "        # context: pseudotime or other context [batch_size, seq_len, context_dim=1]\n",
        "\n",
        "        # pad prot_target to match x_0's sequence length\n",
        "        pad_length = x_0.shape[1] - prot_target.shape[1]\n",
        "        prot_target_padded = F.pad(prot_target, (0, 0, 0, pad_length))\n",
        "\n",
        "        t = torch.rand(x_0.shape[0], device=x_0.device) * (self.T - self.eps) + self.eps\n",
        "        t_expand = t.view(-1, 1, 1).repeat(1, prot_target_padded.shape[1], prot_target_padded.shape[2])\n",
        "\n",
        "        c = c.to(x_0.device)\n",
        "\n",
        "        noise = torch.randn_like(prot_target_padded)\n",
        "        # print(prot_target_padded.shape)\n",
        "        perturbed_target = t_expand * prot_target_padded + (1 - t_expand) * noise\n",
        "\n",
        "        model_out = self.model(x_0, t * 999, c)\n",
        "\n",
        "        # print(\"___________________________________\")\n",
        "        # print(\"loss function params\")\n",
        "        # print(\"model out shape\", model_out.shape)\n",
        "        # print(\"target shape\", prot_target_padded.shape)\n",
        "\n",
        "        loss = F.mse_loss(model_out, prot_target_padded, reduction=\"none\").mean([1, 2]).mean()\n",
        "        # print(\"Pred:\", model_out)\n",
        "        # print(\"Target:\", prot_target_padded)\n",
        "        if torch.isnan(loss).any():\n",
        "          print(\"NaN in loss computation\")\n",
        "          print(\"Pred:\", model_out)\n",
        "          print(\"Target:\", prot_target_padded)\n",
        "        return loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def euler_sample(self, cond, shape, guidance_scale):\n",
        "        device = next(self.model.parameters()).device\n",
        "        cond = cond.to(device)\n",
        "        batch_size, seq_len, _ = shape\n",
        "        x = torch.randn(batch_size, seq_len, self.model.out_channels, device=device)\n",
        "        dt = 1.0 / self.sample_N\n",
        "        eps = 1e-3\n",
        "        for i in range(self.sample_N):\n",
        "            num_t = i / self.sample_N * (self.T - eps) + eps\n",
        "            t = torch.ones(batch_size, device=device) * num_t\n",
        "\n",
        "            model_out = self.model(torch.cat([x] * 2), torch.cat([t.unsqueeze(1)] * 2), cond)\n",
        "            noise_pred_uncond, noise_pred_text = model_out.chunk(2)\n",
        "            pred = noise_pred_uncond + guidance_scale * (noise_pred_text - noise_pred_uncond)\n",
        "\n",
        "            sigma_t = self.sigma_t(num_t)\n",
        "            pred_sigma = pred + (sigma_t**2) / (2 * (self.noise_scale**2) * ((1.0 - num_t) ** 2)) * (\n",
        "                0.5 * num_t * (1.0 - num_t) * pred - 0.5 * (2.0 - num_t) * x\n",
        "            )\n",
        "\n",
        "            x = x + pred_sigma * dt + sigma_t * np.sqrt(dt) * torch.randn_like(x)\n",
        "\n",
        "        return x, self.sample_N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W819YWdTzCi"
      },
      "source": [
        "## train module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21dEMxSOw1ex"
      },
      "source": [
        "### scvi encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KZ5OfT8kPNJ",
        "outputId": "ef2cc8f2-d663-4b4d-c71f-fc690a93a290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "combined_adata_macrophage.h5ad\n",
            "combined_adata_monocyte.h5ad\n",
            "combined_adata_endothelial cell of hepatic sinusoid.h5ad\n",
            "combined_adata_liver dendritic cell.h5ad\n",
            "combined_adata_nk cell.h5ad\n",
            "Read and stored 5 .h5ad files.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import anndata\n",
        "import scvi\n",
        "import os\n",
        "\n",
        "file_count = 0\n",
        "\n",
        "adata_list = []\n",
        "folder_path = '/content/drive/MyDrive/tf-flow-design/combined_adata_folder/'\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith('.h5ad'):\n",
        "        file_path = os.path.join(folder_path, filename)\n",
        "        print(filename)\n",
        "        adata = anndata.read_h5ad(file_path)\n",
        "        adata_list.append(adata)\n",
        "        file_count += 1\n",
        "        if file_count >= 5:\n",
        "            break\n",
        "\n",
        "print(f'Read and stored {file_count} .h5ad files.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "78QR-aHoi5zC"
      },
      "outputs": [],
      "source": [
        "# # Concatenate all AnnData objects\n",
        "# combined_adata = anndata.concat(adata_list, join='outer', label='batch')\n",
        "# print(f\"Combined AnnData shape: {combined_adata.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Lts1Qur2av3d"
      },
      "outputs": [],
      "source": [
        "import anndata\n",
        "\n",
        "adata_dict = {}\n",
        "\n",
        "for adata in adata_list:\n",
        "    # Get the unique cell_ontology_class values (excluding 'mesenchymal stem cell')\n",
        "    cell_types = adata.obs['cell_ontology_class'].unique()\n",
        "    for cell_type in cell_types:\n",
        "        if cell_type != 'mesenchymal stem cell':\n",
        "            if cell_type not in adata_dict:\n",
        "                adata_dict[cell_type] = adata\n",
        "            else:\n",
        "                adata_dict[cell_type] = anndata.concat([adata_dict[cell_type], adata])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxoZTz7QQaP9",
        "outputId": "1bca53e5-1594-4d68-f311-fe6d9034f8e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['macrophage', 'monocyte', 'endothelial cell of hepatic sinusoid', 'liver dendritic cell', 'nk cell'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "adata_dict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8zBTpfQQ5KW",
        "outputId": "d6b8e3bf-4353-4f53-b4a8-572112093a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training and embedding for cell type: macrophage...\n",
            "No NaN values found in adata_copy.X for cell type: macrophage\n",
            "Training and embedding for cell type: monocyte...\n",
            "No NaN values found in adata_copy.X for cell type: monocyte\n",
            "Training and embedding for cell type: endothelial cell of hepatic sinusoid...\n",
            "No NaN values found in adata_copy.X for cell type: endothelial cell of hepatic sinusoid\n",
            "Training and embedding for cell type: liver dendritic cell...\n",
            "No NaN values found in adata_copy.X for cell type: liver dendritic cell\n",
            "Training and embedding for cell type: nk cell...\n",
            "No NaN values found in adata_copy.X for cell type: nk cell\n",
            "Encoding completed.\n"
          ]
        }
      ],
      "source": [
        "scvi_encoder = SCVIEncodingModule()\n",
        "scvi_latents, scvi_pseudotimes = scvi_encoder.encode(adata_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_xhzSQ7v5uU",
        "outputId": "da6fe804-0192-4bbb-dc3c-0ab2d8aa96f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50663, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "scvi_latents['macrophage'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37G0qSqw5mve",
        "outputId": "47fa0626-a6d0-4cad-8854-b93dbda8b1ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50663,)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "scvi_pseudotimes['macrophage'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsBKL442wzXI"
      },
      "source": [
        "### generate random protein sequences for each scvi latent (3 pos, 10 neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG1QHIYTw7lL",
        "outputId": "053ace24-4015-4de9-a4bd-0eadc11d0df8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prot seqs for macrophage:\n",
            "WNEVIRFWIHDEKKQNKWCTEYEINENGWQTGFIPEMGRWDYPNYADCCDVYTAPYGNPQPLASIECDLNVDQAKHPLGHIANFDWWGQADGQGLYLILPTSFRRHFYVFEHGVMMYWENEQYKNHSMEEWSHIRTYAVNWSAVHAAQETIIWKSRLF\n",
            "GTRIKHTLKECDRVFVIKNPNAPEPHNMHIMGAEMQKSDGHIICGSSTAELWLGGNPTKIYENNSEYIGSFPVCMNSYSNGLDPNLMLRRPMYTLDIYEIVAICDIKVRMDDLGMGVDLQAE\n",
            "FNIMSRTPTSMTHYWLVKFRYMHMHARSLLRCCPRDLQGRISMQSTWHMSYMCFFRETNGHADIKSDHDIFDFDFTEYVFDNSQWACFGCHYMLIWWEWQNTVCGPLSEHSNCCDKWYMTCFIVSIIINAKTPNGLECCMFSSRVARKRPLARDIVRCWRIF\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# valid AAs\n",
        "valid_amino_acids = \"ACDEFGHIKLMNPQRSTVWY\"\n",
        "\n",
        "def generate_random_protein_sequence(min_length=100, max_length=200):\n",
        "    length = random.randint(min_length, max_length)\n",
        "    return ''.join(random.choices(valid_amino_acids, k=length))\n",
        "\n",
        "protein_sequences = {}\n",
        "\n",
        "for cell_type in scvi_latents.keys():\n",
        "    protein_sequences[cell_type] = [generate_random_protein_sequence() for _ in range(3)]\n",
        "\n",
        "cell_type_example = 'macrophage'\n",
        "print(f\"prot seqs for {cell_type_example}:\")\n",
        "for seq in protein_sequences[cell_type_example]:\n",
        "    print(seq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAAHts2YyYxk"
      },
      "source": [
        "### datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1xMZflIi0wBg"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "58f6cc9242024e2ab4dcad452cca34af",
            "7ad85806b29f4cba9035cbb4e0ecd517",
            "9889568554c34562a638fe05c4b5fd6b",
            "05b92fec95b04904ab99c8e9c4b17263",
            "9879c09284a145a1af5b1d6c5a01d974",
            "2ce804609376412f84cff0e085e616ed",
            "422b40e5c4514434aeed1d9ba35cedea",
            "dac64146cd5d40d69c6ee2fd9063726b",
            "b5e51e896383402aafdf514540ebd2aa",
            "eeae93d0587848d2bfa62f69a412b4e4",
            "21c47cfa713544238f7d9f41047a88d6",
            "a4e333ea3cea4c7fbc0c93df82e07bef",
            "da290f249c724fbf81482a8b7e820cf3",
            "e4119d0790894c0b9cfa96996c332dff",
            "42d2691322e74fae8d5cf1e773adf182",
            "81f0b39a7afe408887ff12708b711ab7",
            "a2b69f3410e846e59afe4e4c6abe14a8",
            "38064267a86347f08907c0688c745f82",
            "c9e8c805874d47d287b2a76472152402",
            "bd0113ab022145219313832b6e48062c",
            "7946a56f374d44cba2e5767976d9384a",
            "ff212b17f9cf485e8ed83df1fcd26d78",
            "dc7b1a5ca1894d4dbb254c171d0022dd",
            "804fada6d58a4fc78eac0247a26084a0",
            "20aa33586a95411f842eea7fc4f975ce",
            "d42cb197829147b395900a4bc2ad7d5e",
            "92c8f62bc01a407db9a67d130bf9ba72",
            "ea50c2ecd600426892b7067247f7075d",
            "b8acd50b070e403188a94d5418a3a1e0",
            "8bb92d57d8b04d40a38cc9eba74b1bf8",
            "2ba8af2091e84152ba98f0f4754a681f",
            "2a9cd928d0ce4af3b049ee7786fc909c",
            "596591aefb46447faafb428c9f7fcbd3",
            "33def47993e4469fb5657c2fa3b6ad81",
            "c1efb188c3584a3fb2b26d47bba2e360",
            "203cf4c8c2e04d69ac17bb019e8fa786",
            "620d4d0d10a34706931cea0911eac9b3",
            "1f071510459c46c29b582d1cfba896a6",
            "399d4d784046417b8e0c72664bdf9aa8",
            "42d8b3c750a847c3b9d5bded5b402e9a",
            "4d718b8f09d546fea81adaf9a75df143",
            "0331b6ef187447b2b92d99db8a83d884",
            "f79a1adb427643efabb1be6f70031edb",
            "df342f429dd74f11b8d40cc72b54a0a4",
            "c1e5327e36e04fdfb92b55dd9b8d209e",
            "feb1c0478315438b926447737b8e71f9",
            "a5c58e8233f447689948ed2ea4dbce91",
            "99b61a1cb60c47d8893b99346792cf2c",
            "0a258d1e8a3f4d62a627b69717ee72a8",
            "e13edf63e8e84c458919d55af1a478a6",
            "154bb13f43414a96940b2c35eff13923",
            "af615136d7924c22865da81ded674237",
            "731ef2af3eed40cf949f2e504524b246",
            "6c1c4b2bd16741da9134460b38aca1f0",
            "f66958a466044d3189152e2136c2832b",
            "247a334a094b4b20a6d0a2304617af6f",
            "165db12f02dc4ee793e237566729c1b8",
            "1976e08db9844ddcb1fa37f8645a5250",
            "85829e61d1514fcca68c4660d9cd55ad",
            "8e2af049805b4cf69466331789499255",
            "267aba960cac44e88dd085a1c598b7c4",
            "a3467168125c4e43bbaa6d9ff1048967",
            "0354c8ea54f0447a9d34c4b7d657c4d0",
            "6de59bf31ad74e0eb0e292017bf38edf",
            "f2a17a2210a548a281d2ef04187b593f",
            "a5244925129348e78d97b4b5204d9e00"
          ]
        },
        "id": "jc9X0I6-0YQq",
        "outputId": "f82e6415-a3e0-4e3d-b095-9f411e6e14e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/656 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58f6cc9242024e2ab4dcad452cca34af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4e333ea3cea4c7fbc0c93df82e07bef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dc7b1a5ca1894d4dbb254c171d0022dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/238k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33def47993e4469fb5657c2fa3b6ad81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e5327e36e04fdfb92b55dd9b8d209e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/457 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "247a334a094b4b20a6d0a2304617af6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell type: macrophage, Latent shape: (50663, 50), Sequence length: 158, Pseudotime shape: (50663,)\n",
            "Cell type: macrophage, Latent shape: (50663, 50), Sequence length: 122, Pseudotime shape: (50663,)\n",
            "Cell type: macrophage, Latent shape: (50663, 50), Sequence length: 162, Pseudotime shape: (50663,)\n",
            "Cell type: monocyte, Latent shape: (27973, 50), Sequence length: 152, Pseudotime shape: (27973,)\n",
            "Cell type: monocyte, Latent shape: (27973, 50), Sequence length: 198, Pseudotime shape: (27973,)\n",
            "Cell type: monocyte, Latent shape: (27973, 50), Sequence length: 117, Pseudotime shape: (27973,)\n",
            "Cell type: endothelial cell of hepatic sinusoid, Latent shape: (15880, 50), Sequence length: 118, Pseudotime shape: (15880,)\n",
            "Cell type: endothelial cell of hepatic sinusoid, Latent shape: (15880, 50), Sequence length: 172, Pseudotime shape: (15880,)\n",
            "Cell type: endothelial cell of hepatic sinusoid, Latent shape: (15880, 50), Sequence length: 148, Pseudotime shape: (15880,)\n",
            "Cell type: liver dendritic cell, Latent shape: (15493, 50), Sequence length: 169, Pseudotime shape: (15493,)\n",
            "Cell type: liver dendritic cell, Latent shape: (15493, 50), Sequence length: 152, Pseudotime shape: (15493,)\n",
            "Cell type: liver dendritic cell, Latent shape: (15493, 50), Sequence length: 150, Pseudotime shape: (15493,)\n",
            "Cell type: nk cell, Latent shape: (24315, 50), Sequence length: 182, Pseudotime shape: (24315,)\n",
            "Cell type: nk cell, Latent shape: (24315, 50), Sequence length: 170, Pseudotime shape: (24315,)\n",
            "Cell type: nk cell, Latent shape: (24315, 50), Sequence length: 140, Pseudotime shape: (24315,)\n"
          ]
        }
      ],
      "source": [
        "encoder = ProtT5EncodingModule()\n",
        "\n",
        "latent_list = []\n",
        "pseudotime_list = []\n",
        "sequence_list = []\n",
        "\n",
        "for cell_type, latents in scvi_latents.items():\n",
        "    pseudotimes = scvi_pseudotimes[cell_type]\n",
        "    for latent, pseudotime, sequence in zip(latents, pseudotimes, protein_sequences[cell_type]):\n",
        "        print(f\"Cell type: {cell_type}, Latent shape: {latents.shape}, Sequence length: {len(sequence)}, Pseudotime shape: {pseudotimes.shape}\")\n",
        "        latent_list.append(latents)\n",
        "        pseudotime_list.append(pseudotimes)\n",
        "        sequence_list.append(sequence)\n",
        "\n",
        "# seqs encoding protT5\n",
        "sequence_tensor_list = []\n",
        "for sequence in sequence_list:\n",
        "    sequence_tensor = encoder(sequence)\n",
        "    sequence_tensor_list.append(sequence_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g6OvPn_1Dpx",
        "outputId": "33a41e66-22d5-4060-adea-43a1a68caf93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 159, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "sequence_tensor_list[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Bqj90ko108cF"
      },
      "outputs": [],
      "source": [
        "\n",
        "# pad\n",
        "max_len = max(sequence.shape[1] for sequence in sequence_tensor_list)\n",
        "padded_sequence_tensor_list = [\n",
        "    torch.cat([sequence, torch.zeros(1, max_len - sequence.shape[1], sequence.shape[2], dtype=sequence.dtype)], dim=1)\n",
        "    if sequence.shape[1] < max_len else sequence for sequence in sequence_tensor_list\n",
        "]\n",
        "sequence_tensor = torch.cat(padded_sequence_tensor_list, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vUDzJ6h3g0d",
        "outputId": "e741f5ce-fc24-412a-9fc1-d09956dec581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 199, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "sequence_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7_YDnHv6eYw",
        "outputId": "9b15f275-fca5-4262-f0b4-188e5aeab79c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50663, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "latent_list[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Funv8saA2pIG"
      },
      "outputs": [],
      "source": [
        "latent_tensor_list = [torch.tensor(latent, dtype=torch.float32) for latent in latent_list]\n",
        "\n",
        "max_len = max(latent.shape[0] for latent in latent_tensor_list)\n",
        "\n",
        "padded_latent_list = [\n",
        "    torch.cat([latent, torch.zeros((max_len - latent.shape[0], latent.shape[1]), dtype=latent.dtype)], dim=0)\n",
        "    if latent.shape[0] < max_len else latent for latent in latent_tensor_list\n",
        "]\n",
        "\n",
        "# instead of padding (low compute -> project sequence layer down to 1024 dim and train (current at 50K))\n",
        "class SequenceProjector(nn.Module):\n",
        "    def __init__(self, seq_len, d_output=1024, d_hidden=256):\n",
        "        super().__init__()\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(seq_len, d_hidden),\n",
        "            nn.LayerNorm(d_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            nn.LayerNorm(d_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(d_hidden, d_output)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, emb_dim)\n",
        "        batch_size, seq_len, emb_dim = x.shape\n",
        "\n",
        "        # Transpose to (batch_size, emb_dim, seq_len)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        # Project sequence length to d_output\n",
        "        x = self.projector(x)  # Shape: (batch_size, emb_dim, d_output)\n",
        "\n",
        "        # Transpose back to (batch_size, d_output, emb_dim)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Usage\n",
        "seq_len = padded_latent_list[0].shape[0]  # Original sequence length\n",
        "d_output = 1024  # Desired output sequence length\n",
        "emb_dim = padded_latent_list[0].shape[1]  # Original embedding dimension (50)\n",
        "\n",
        "sequence_projector = SequenceProjector(seq_len, d_output)\n",
        "\n",
        "projected_latents = []\n",
        "for latent in padded_latent_list:\n",
        "    projected = sequence_projector(latent.unsqueeze(0))  # Add batch dimension if needed\n",
        "    projected_latents.append(projected.squeeze(0))  # Remove batch dimension if added\n",
        "\n",
        "latent_tensor = torch.stack(projected_latents, dim=0)\n",
        "\n",
        "# latent_tensor = torch.stack(padded_latent_list, dim=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvUO7Z3K3xES",
        "outputId": "0631fb65-e626-432d-b494-dabaadc0c84d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 1024, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "latent_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS86ezG-3Rns",
        "outputId": "bdb6dc82-73d4-465c-f268-dc117f1552db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cell_ontology_class\n",
            "macrophage               35204\n",
            "mesenchymal stem cell    15459\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "### pseudotime as a context:\n",
        "adata_list[0].obs['dpt_pseudotime'].shape\n",
        "unique_counts = adata_list[0].obs['cell_ontology_class'].value_counts()\n",
        "print(unique_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvKatCSV70-m",
        "outputId": "20bfc5f5-0327-4e0c-8fe8-8b9edcf1bc88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-f91bad088d9a>:1: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  pseudotime_tensor_list = [torch.tensor(pseudotime, dtype=torch.float32) for pseudotime in pseudotime_list]\n"
          ]
        }
      ],
      "source": [
        "pseudotime_tensor_list = [torch.tensor(pseudotime, dtype=torch.float32) for pseudotime in pseudotime_list]\n",
        "\n",
        "# ensure pseudotime tensors have shape (seqlen, 1) before padding\n",
        "pseudotime_tensor_list = [\n",
        "    pseudotime if len(pseudotime.shape) == 2 else pseudotime.unsqueeze(1) for pseudotime in pseudotime_tensor_list\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NHiB_2nk8Fig"
      },
      "outputs": [],
      "source": [
        "max_pseudotime_len = max(pseudotime.shape[0] for pseudotime in pseudotime_tensor_list)\n",
        "\n",
        "padded_pseudotime_tensor_list = [\n",
        "    torch.cat([pseudotime, torch.zeros((max_pseudotime_len - pseudotime.shape[0], pseudotime.shape[1]), dtype=pseudotime.dtype)], dim=0)\n",
        "    if pseudotime.shape[0] < max_pseudotime_len else pseudotime for pseudotime in pseudotime_tensor_list\n",
        "]\n",
        "\n",
        "pseudotime_tensor = torch.stack(padded_pseudotime_tensor_list, dim=0)\n",
        "\n",
        "class SequenceProjector(nn.Module):\n",
        "    def __init__(self, seq_len, d_output=1024, d_hidden=256):\n",
        "        super().__init__()\n",
        "        self.projector = nn.Sequential(\n",
        "            nn.Linear(seq_len, d_hidden),\n",
        "            nn.LayerNorm(d_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(d_hidden, d_hidden),\n",
        "            nn.LayerNorm(d_hidden),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(d_hidden, d_output)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, emb_dim)\n",
        "        batch_size, seq_len, emb_dim = x.shape\n",
        "\n",
        "        # Transpose to (batch_size, emb_dim, seq_len)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        # Project sequence length to d_output\n",
        "        x = self.projector(x)  # Shape: (batch_size, emb_dim, d_output)\n",
        "\n",
        "        # Transpose back to (batch_size, d_output, emb_dim)\n",
        "        x = x.transpose(1, 2)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Usage\n",
        "seq_len = padded_pseudotime_tensor_list[0].shape[0]  # Original sequence length\n",
        "d_output = 1024  # Desired output sequence length\n",
        "emb_dim = padded_pseudotime_tensor_list[0].shape[1]  # Original embedding dimension (50)\n",
        "\n",
        "sequence_projector = SequenceProjector(seq_len, d_output)\n",
        "\n",
        "projected_latents = []\n",
        "for latent in padded_pseudotime_tensor_list:\n",
        "    projected = sequence_projector(latent.unsqueeze(0))  # Add batch dimension if needed\n",
        "    projected_latents.append(projected.squeeze(0))  # Remove batch dimension if added\n",
        "\n",
        "pseudotime_tensor = torch.stack(projected_latents, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlYN6aGh84XI",
        "outputId": "f7185c97-0a6b-4891-c519-fe28e57f8516"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 1024, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "pseudotime_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "vGgHwRuM-Rdf"
      },
      "outputs": [],
      "source": [
        "# seq dim = 1024, latent dim = 50, pseudotime dim = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "kdqzZHCk_HWc"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "full_dataset = TensorDataset(latent_tensor, pseudotime_tensor, sequence_tensor)\n",
        "\n",
        "# split size calculation\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = total_size - train_size\n",
        "\n",
        "# dataset split\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# dataloader creation\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEu3MrI3_SC3",
        "outputId": "20e22787-96d8-488a-cd25-a513a5c2c1e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f884fb3c250>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "train_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2D220eTz-0L",
        "outputId": "229fda3d-a269-411a-f5ec-b42e84a85942"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 1024, 50])\n",
            "torch.Size([2, 199, 1024])\n",
            "torch.Size([2, 1024, 1])\n",
            "torch.Size([2, 1024, 50])\n",
            "torch.Size([2, 199, 1024])\n",
            "torch.Size([2, 1024, 1])\n",
            "torch.Size([2, 1024, 50])\n",
            "torch.Size([2, 199, 1024])\n",
            "torch.Size([2, 1024, 1])\n",
            "torch.Size([2, 1024, 50])\n",
            "torch.Size([2, 199, 1024])\n",
            "torch.Size([2, 1024, 1])\n",
            "torch.Size([2, 1024, 50])\n",
            "torch.Size([2, 199, 1024])\n",
            "torch.Size([2, 1024, 1])\n"
          ]
        }
      ],
      "source": [
        "for batch in train_dataloader:\n",
        "    scvi, dpt, seq = batch\n",
        "    print(scvi.shape)\n",
        "    print(seq.shape)\n",
        "    print(dpt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpCeq3tdyZv0"
      },
      "source": [
        "### models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "VwYmnDMhLbdO"
      },
      "outputs": [],
      "source": [
        "class ProteinFlowMatching(nn.Module):\n",
        "    def __init__(self, flow_matching, decoder):\n",
        "        super().__init__()\n",
        "        self.flow_matching = flow_matching\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x, target, context):\n",
        "        return self.flow_matching(x, target, context) # training: loss from the flowmatching module\n",
        "\n",
        "    def generate(self, x, context, num_steps=200):\n",
        "        device = next(self.parameters()).device\n",
        "        x = x.to(device)\n",
        "        context = context.to(device)\n",
        "        latent = self.flow_matching.euler_sample(context, x.shape, guidance_scale=3.0)[0]\n",
        "        protein_sequence = self.decoder(latent, max_length=num_steps)\n",
        "        return protein_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "b8d3f9e368e644899d1b605f45cc0176",
            "6bcb96f066c6497faacaad1be65dcec7",
            "0a3a488d582c453997ddd9852dad5e7f",
            "e855389934914b0b849e436b80782363",
            "53f35e546904419c99a177387f404af4",
            "00c68cbd3f5342728861a3818c11ca80",
            "07ebec32879d48fd860f30fb37c60abe",
            "cba1d8cdfb434d33b0270f68351e586c",
            "c397fdb7cedb49ddaadfbae669bcdee3",
            "b90fe953d33b40a4a348b75e7da7ab79",
            "498cd7a392624542addae3750fb10ebd"
          ]
        },
        "id": "_oRb8_B9wLnH",
        "outputId": "bd2f5b9a-be57-40ee-cb7c-2ee33071e75a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/11.3G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8d3f9e368e644899d1b605f45cc0176"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, (nn.Linear, nn.Conv1d)):\n",
        "        nn.init.xavier_uniform_(m.weight)\n",
        "        if m.bias is not None:\n",
        "            nn.init.zeros_(m.bias)\n",
        "\n",
        "# Initialize models\n",
        "unet = CustomUNet1D(\n",
        "    in_channels=50,  # Dimension of scVI latents\n",
        "    out_channels=1024,  # Dimension of protein embeddings\n",
        "    model_channels=64,\n",
        "    num_res_blocks=2,\n",
        "    attention_resolutions=(1,),\n",
        "    dropout=0.1,\n",
        "    channel_mult=(1, 2, 4, 8),\n",
        "    use_spatial_transformer=True,\n",
        "    transformer_depth=1,\n",
        "    context_dim=1,  # Dimension of pseudotime\n",
        ")\n",
        "\n",
        "unet.apply(init_weights)\n",
        "\n",
        "flow_matching = FlowMatchingTrainer(unet, sample_N=25)\n",
        "decoder = ProtT5DecodingModule()  # vocab_size is the number of amino acids + special tokens\n",
        "model = ProteinFlowMatching(flow_matching, decoder)\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVlSfboYplb7"
      },
      "source": [
        "### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCS9pXSrzHrB",
        "outputId": "9f1ac67d-8838-4d93-e790-72a16755f91d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Train Loss: 0.0459, Val Loss: 0.0439\n",
            "New best model saved with validation loss: 0.0439\n"
          ]
        }
      ],
      "source": [
        "\n",
        "num_epochs = 1\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "\n",
        "def prepare_pseudotime(pseudotime):\n",
        "    # replace NaNs with -1000 (or any other value outside the -1 to 1 range)\n",
        "    pseudotime = torch.where(torch.isnan(pseudotime), torch.tensor(-1000.0).to(pseudotime.device), pseudotime)\n",
        "    # create a mask for valid values\n",
        "    mask = (pseudotime != -1000).float()\n",
        "    return pseudotime, mask\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for scvi_latent, pseudotime, protein_seq in train_dataloader:\n",
        "        scvi_latent = scvi_latent.to(device)\n",
        "        pseudotime = pseudotime.to(device)\n",
        "        protein_seq = protein_seq.to(device)\n",
        "\n",
        "        scvi_latent = scvi_latent.detach().clone()\n",
        "        pseudotime, pseudotime_mask = prepare_pseudotime(pseudotime.detach().clone()) # fixed nans in pseudotime\n",
        "        protein_seq = protein_seq.detach().clone()\n",
        "        # print(pseudotime)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = model(scvi_latent, protein_seq, pseudotime)  # forward pass through ProteinFlowMatching\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # gradient clipping\n",
        "\n",
        "        # for name, param in model.named_parameters():\n",
        "        #     if param.grad is not None:\n",
        "        #         print(f\"{name} grad norm: {param.grad.norm()}\") # exploding gradient check\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_dataloader)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for scvi_latent, pseudotime, protein_seq in val_dataloader:\n",
        "            scvi_latent = scvi_latent.to(device)\n",
        "            pseudotime, pseudotime_mask = prepare_pseudotime(pseudotime.detach().clone()) # nans in pseudotime\n",
        "            protein_seq = protein_seq.to(device)\n",
        "            loss = model(scvi_latent, protein_seq, pseudotime)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Save the best model\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), 'best_model.pth')\n",
        "        print(f\"New best model saved with validation loss: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "wxPhbYMMbOPR",
        "outputId": "15d87176-77ac-42e9-8678-f2921ef4310c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [64, 50, 3], expected input[4, 1024, 2000] to have 50 channels, but got 1024 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-994c36fb4cfe>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mscvi_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# random scVI latent with batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpseudotime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# random pseudotime with batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mgenerated_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscvi_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpseudotime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generated sequence:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-f4c3df90d4d5>\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, x, context, num_steps)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow_matching\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuler_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mprotein_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprotein_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-2527027d2532>\u001b[0m in \u001b[0;36meuler_sample\u001b[0;34m(self, cond, shape, guidance_scale)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mnoise_pred_uncond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_pred_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_pred_uncond\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mguidance_scale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnoise_pred_text\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnoise_pred_uncond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-6873af1ab32d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, timesteps, context)\u001b[0m\n\u001b[1;32m    144\u001b[0m           \u001b[0;31m# print(\"Module type input blocks:\", type(module))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m               \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m           \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpatialTransformer1D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 50, 3], expected input[4, 1024, 2000] to have 50 channels, but got 1024 channels instead"
          ]
        }
      ],
      "source": [
        "# generate new protein sequences\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    device = next(model.parameters()).device\n",
        "    scvi_latent = torch.randn(2,2000, 50).to(device)  # random scVI latent with batch size\n",
        "    pseudotime = torch.rand(2, 2000, 1).to(device)  # random pseudotime with batch size\n",
        "    generated_sequence = model.generate(scvi_latent, pseudotime)\n",
        "    print(\"Generated sequence:\", generated_sequence)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "GxlZK1SHkgl9",
        "b-njBgLzltjL",
        "X-e-EUQyklC2",
        "ht7z5O8ilEnK",
        "PBEPeCXzk3zn",
        "zOjxMpSTljVi",
        "21dEMxSOw1ex",
        "JsBKL442wzXI",
        "lAAHts2YyYxk"
      ],
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58f6cc9242024e2ab4dcad452cca34af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ad85806b29f4cba9035cbb4e0ecd517",
              "IPY_MODEL_9889568554c34562a638fe05c4b5fd6b",
              "IPY_MODEL_05b92fec95b04904ab99c8e9c4b17263"
            ],
            "layout": "IPY_MODEL_9879c09284a145a1af5b1d6c5a01d974"
          }
        },
        "7ad85806b29f4cba9035cbb4e0ecd517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ce804609376412f84cff0e085e616ed",
            "placeholder": "​",
            "style": "IPY_MODEL_422b40e5c4514434aeed1d9ba35cedea",
            "value": "config.json: 100%"
          }
        },
        "9889568554c34562a638fe05c4b5fd6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dac64146cd5d40d69c6ee2fd9063726b",
            "max": 656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5e51e896383402aafdf514540ebd2aa",
            "value": 656
          }
        },
        "05b92fec95b04904ab99c8e9c4b17263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeae93d0587848d2bfa62f69a412b4e4",
            "placeholder": "​",
            "style": "IPY_MODEL_21c47cfa713544238f7d9f41047a88d6",
            "value": " 656/656 [00:00&lt;00:00, 53.1kB/s]"
          }
        },
        "9879c09284a145a1af5b1d6c5a01d974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce804609376412f84cff0e085e616ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422b40e5c4514434aeed1d9ba35cedea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dac64146cd5d40d69c6ee2fd9063726b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5e51e896383402aafdf514540ebd2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eeae93d0587848d2bfa62f69a412b4e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21c47cfa713544238f7d9f41047a88d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4e333ea3cea4c7fbc0c93df82e07bef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da290f249c724fbf81482a8b7e820cf3",
              "IPY_MODEL_e4119d0790894c0b9cfa96996c332dff",
              "IPY_MODEL_42d2691322e74fae8d5cf1e773adf182"
            ],
            "layout": "IPY_MODEL_81f0b39a7afe408887ff12708b711ab7"
          }
        },
        "da290f249c724fbf81482a8b7e820cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2b69f3410e846e59afe4e4c6abe14a8",
            "placeholder": "​",
            "style": "IPY_MODEL_38064267a86347f08907c0688c745f82",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "e4119d0790894c0b9cfa96996c332dff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9e8c805874d47d287b2a76472152402",
            "max": 2416373051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd0113ab022145219313832b6e48062c",
            "value": 2416373051
          }
        },
        "42d2691322e74fae8d5cf1e773adf182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7946a56f374d44cba2e5767976d9384a",
            "placeholder": "​",
            "style": "IPY_MODEL_ff212b17f9cf485e8ed83df1fcd26d78",
            "value": " 2.42G/2.42G [00:21&lt;00:00, 126MB/s]"
          }
        },
        "81f0b39a7afe408887ff12708b711ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b69f3410e846e59afe4e4c6abe14a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38064267a86347f08907c0688c745f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9e8c805874d47d287b2a76472152402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd0113ab022145219313832b6e48062c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7946a56f374d44cba2e5767976d9384a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff212b17f9cf485e8ed83df1fcd26d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc7b1a5ca1894d4dbb254c171d0022dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_804fada6d58a4fc78eac0247a26084a0",
              "IPY_MODEL_20aa33586a95411f842eea7fc4f975ce",
              "IPY_MODEL_d42cb197829147b395900a4bc2ad7d5e"
            ],
            "layout": "IPY_MODEL_92c8f62bc01a407db9a67d130bf9ba72"
          }
        },
        "804fada6d58a4fc78eac0247a26084a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea50c2ecd600426892b7067247f7075d",
            "placeholder": "​",
            "style": "IPY_MODEL_b8acd50b070e403188a94d5418a3a1e0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "20aa33586a95411f842eea7fc4f975ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb92d57d8b04d40a38cc9eba74b1bf8",
            "max": 24,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ba8af2091e84152ba98f0f4754a681f",
            "value": 24
          }
        },
        "d42cb197829147b395900a4bc2ad7d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a9cd928d0ce4af3b049ee7786fc909c",
            "placeholder": "​",
            "style": "IPY_MODEL_596591aefb46447faafb428c9f7fcbd3",
            "value": " 24.0/24.0 [00:00&lt;00:00, 2.09kB/s]"
          }
        },
        "92c8f62bc01a407db9a67d130bf9ba72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea50c2ecd600426892b7067247f7075d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8acd50b070e403188a94d5418a3a1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb92d57d8b04d40a38cc9eba74b1bf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba8af2091e84152ba98f0f4754a681f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a9cd928d0ce4af3b049ee7786fc909c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596591aefb46447faafb428c9f7fcbd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "33def47993e4469fb5657c2fa3b6ad81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1efb188c3584a3fb2b26d47bba2e360",
              "IPY_MODEL_203cf4c8c2e04d69ac17bb019e8fa786",
              "IPY_MODEL_620d4d0d10a34706931cea0911eac9b3"
            ],
            "layout": "IPY_MODEL_1f071510459c46c29b582d1cfba896a6"
          }
        },
        "c1efb188c3584a3fb2b26d47bba2e360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_399d4d784046417b8e0c72664bdf9aa8",
            "placeholder": "​",
            "style": "IPY_MODEL_42d8b3c750a847c3b9d5bded5b402e9a",
            "value": "spiece.model: 100%"
          }
        },
        "203cf4c8c2e04d69ac17bb019e8fa786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d718b8f09d546fea81adaf9a75df143",
            "max": 237990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0331b6ef187447b2b92d99db8a83d884",
            "value": 237990
          }
        },
        "620d4d0d10a34706931cea0911eac9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f79a1adb427643efabb1be6f70031edb",
            "placeholder": "​",
            "style": "IPY_MODEL_df342f429dd74f11b8d40cc72b54a0a4",
            "value": " 238k/238k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "1f071510459c46c29b582d1cfba896a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "399d4d784046417b8e0c72664bdf9aa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d8b3c750a847c3b9d5bded5b402e9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d718b8f09d546fea81adaf9a75df143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0331b6ef187447b2b92d99db8a83d884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f79a1adb427643efabb1be6f70031edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df342f429dd74f11b8d40cc72b54a0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e5327e36e04fdfb92b55dd9b8d209e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feb1c0478315438b926447737b8e71f9",
              "IPY_MODEL_a5c58e8233f447689948ed2ea4dbce91",
              "IPY_MODEL_99b61a1cb60c47d8893b99346792cf2c"
            ],
            "layout": "IPY_MODEL_0a258d1e8a3f4d62a627b69717ee72a8"
          }
        },
        "feb1c0478315438b926447737b8e71f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e13edf63e8e84c458919d55af1a478a6",
            "placeholder": "​",
            "style": "IPY_MODEL_154bb13f43414a96940b2c35eff13923",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a5c58e8233f447689948ed2ea4dbce91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af615136d7924c22865da81ded674237",
            "max": 1786,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_731ef2af3eed40cf949f2e504524b246",
            "value": 1786
          }
        },
        "99b61a1cb60c47d8893b99346792cf2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1c4b2bd16741da9134460b38aca1f0",
            "placeholder": "​",
            "style": "IPY_MODEL_f66958a466044d3189152e2136c2832b",
            "value": " 1.79k/1.79k [00:00&lt;00:00, 149kB/s]"
          }
        },
        "0a258d1e8a3f4d62a627b69717ee72a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e13edf63e8e84c458919d55af1a478a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "154bb13f43414a96940b2c35eff13923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af615136d7924c22865da81ded674237": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "731ef2af3eed40cf949f2e504524b246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c1c4b2bd16741da9134460b38aca1f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f66958a466044d3189152e2136c2832b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "247a334a094b4b20a6d0a2304617af6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_165db12f02dc4ee793e237566729c1b8",
              "IPY_MODEL_1976e08db9844ddcb1fa37f8645a5250",
              "IPY_MODEL_85829e61d1514fcca68c4660d9cd55ad"
            ],
            "layout": "IPY_MODEL_8e2af049805b4cf69466331789499255"
          }
        },
        "165db12f02dc4ee793e237566729c1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_267aba960cac44e88dd085a1c598b7c4",
            "placeholder": "​",
            "style": "IPY_MODEL_a3467168125c4e43bbaa6d9ff1048967",
            "value": "config.json: 100%"
          }
        },
        "1976e08db9844ddcb1fa37f8645a5250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0354c8ea54f0447a9d34c4b7d657c4d0",
            "max": 457,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6de59bf31ad74e0eb0e292017bf38edf",
            "value": 457
          }
        },
        "85829e61d1514fcca68c4660d9cd55ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2a17a2210a548a281d2ef04187b593f",
            "placeholder": "​",
            "style": "IPY_MODEL_a5244925129348e78d97b4b5204d9e00",
            "value": " 457/457 [00:00&lt;00:00, 38.5kB/s]"
          }
        },
        "8e2af049805b4cf69466331789499255": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267aba960cac44e88dd085a1c598b7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3467168125c4e43bbaa6d9ff1048967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0354c8ea54f0447a9d34c4b7d657c4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de59bf31ad74e0eb0e292017bf38edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2a17a2210a548a281d2ef04187b593f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5244925129348e78d97b4b5204d9e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8d3f9e368e644899d1b605f45cc0176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bcb96f066c6497faacaad1be65dcec7",
              "IPY_MODEL_0a3a488d582c453997ddd9852dad5e7f",
              "IPY_MODEL_e855389934914b0b849e436b80782363"
            ],
            "layout": "IPY_MODEL_53f35e546904419c99a177387f404af4"
          }
        },
        "6bcb96f066c6497faacaad1be65dcec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00c68cbd3f5342728861a3818c11ca80",
            "placeholder": "​",
            "style": "IPY_MODEL_07ebec32879d48fd860f30fb37c60abe",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0a3a488d582c453997ddd9852dad5e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cba1d8cdfb434d33b0270f68351e586c",
            "max": 11275562268,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c397fdb7cedb49ddaadfbae669bcdee3",
            "value": 11275562268
          }
        },
        "e855389934914b0b849e436b80782363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b90fe953d33b40a4a348b75e7da7ab79",
            "placeholder": "​",
            "style": "IPY_MODEL_498cd7a392624542addae3750fb10ebd",
            "value": " 11.3G/11.3G [01:16&lt;00:00, 200MB/s]"
          }
        },
        "53f35e546904419c99a177387f404af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00c68cbd3f5342728861a3818c11ca80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ebec32879d48fd860f30fb37c60abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cba1d8cdfb434d33b0270f68351e586c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c397fdb7cedb49ddaadfbae669bcdee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b90fe953d33b40a4a348b75e7da7ab79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498cd7a392624542addae3750fb10ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
